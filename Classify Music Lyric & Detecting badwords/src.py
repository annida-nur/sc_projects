# -*- coding: utf-8 -*-
"""Classify Music Lyric & Detecting badwords.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QnAoh8jE6KnRj_E34Q7TEcUKiG4bElsX

# **Library**
"""

import pandas as pd
import re
import numpy as np
import sklearn
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import FeatureUnion
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import classification_report
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction import text
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn import model_selection
from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')

"""# **Prepare Dataset**

Dataset yang digunakan berupa file 2 file CSV. Dimana file tersebut memiliki atribut-atribut sebagai berikut :
- artist : memuat nama penyanyi
- song : memuat judul lagu
- lirik : memuat lirik lagu
- Label : memuat kategori/label lagu (true : mengandung badwords, false : tidak mengandung badwords)
"""

# dataset 1

df1 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/ML Semester 5/TUBES/asset/lirik/songs lyric.csv")
df1 = df1[['artist','song','lirik','Label']]
df1 = df1.loc[df1['Label'] != 'no match']
#remove'\n' from the lyrics
re_drop = re.compile(r'\n')        
df1[['lirik']] = df1[['lirik']].applymap(lambda x:re_drop.sub(' ',x))

df1

# dataset 2
df2 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/ML Semester 5/TUBES/asset/lirik/subsongdata_57650.csv")
df2 = df2[['artist','song','text','explicit_label']]
df2 = df2.loc[df2['explicit_label'] != 'no match']
#remove'\n' from the lyrics
re_drop = re.compile(r'\n')        
df2[['text']] = df2[['text']].applymap(lambda x:re_drop.sub(' ',x))
df2.rename(columns = {"text": "lirik", "explicit_label": "Label"}, inplace=True)

df2

# menggabungkan 2 dataframe
song_df = pd.merge(df1,df2,how="outer")

song_df

"""# **Preprocessing**

**Import Stopword**
"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# menggunakan 2 bahasa karena dataset yang digunakan meliputi 2 bahasa tersebut
idn_stopwords = set(stopwords.words('indonesian'))
eng_stopwords = set(stopwords.words('english'))

filtering = set(idn_stopwords)
filtering.update(eng_stopwords)

filtering

len(filtering)

"""**Cleaning**"""

#fungsi untuk menghapus semua karakter non-alfabet pada atribut lirik
def clean(text):
  text = re.sub('[^A-Za-z]+', ' ', text)
  return text
#lowercase
def casefolding(tweet):
  tweet = tweet.lower()
  tweet = tweet.strip(" ")
  tweet = re.sub(r'[?|$|.|!Â²_:")(-+.]','',tweet)
  return tweet

song_df['lirik'] = song_df['lirik'].apply(clean)
song_df['lirik'] = song_df['lirik'].apply(casefolding)
song_df

"""**Mengatasi Ketidak-konsitenan pada atribute Label**"""

for i in range(song_df.shape[0]):
    l = song_df['Label'][i]
    if l==False:
      l = 'False'
    elif l==True :
      l = 'True'
    song_df['Label'][i] = l

song_df['Label'].values

song_df[(song_df['Label']=='False')].shape

song_df[(song_df['Label']=='True')].shape

"""# **Training**

**Split Data**
"""

song_df_1 = song_df.loc[song_df['Label'] == 'True']
song_df_0 = song_df.loc[song_df['Label'] == 'False']
song_df_0 = song_df_0.sample(n=23418, replace=False, random_state=100)

x = song_df_0[['artist','song','lirik']].append(song_df_1[['artist','song','lirik']])
y = song_df_0[['Label']].append(song_df_1[['Label']])

#train : test = 8 : 2
x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=4961, random_state=100)

x_train

y_train

x_test

y_test

# mengubah type data train_label, test_label, train_data, test_data
train_label = []
for i in range(len(y_train)):
    l = y_train.iloc[i,0]
    if l=='False':
      l = 0
    else :
      l = 1
    train_label.append(l)

test_label = []
for i in range(len(y_test)):
    l = y_test.iloc[i,0]
    if l=='False':
      l = 0
    else:
      l = 1
    test_label.append(l)
    
train_data = []
for i in range(len(x_train)):
    text = x_train.iloc[i,2]
    train_data.append(text)
    
test_data = []
for i in range(len(x_test)):
    text = x_test.iloc[i,2]
    test_data.append(text)

type(test_data)

"""**Custom Feature**"""

file1 = open('/content/drive/MyDrive/Colab Notebooks/ML Semester 5/TUBES/asset/badwords/indonesian.csv','r')
file2 = open('/content/drive/MyDrive/Colab Notebooks/ML Semester 5/TUBES/asset/badwords/badwords.txt','r')
file1 = list(file1)
file2 = list(file2)

bad_words= []
for w in file1:
    bad_words.append(re.sub(r'\n','',w))
for w in file2:
    bad_words.append(re.sub(r'\n','',w))

bad_words

len(bad_words)

def get_bad_words(review):
  target_word = bad_words
  count = 0
  threshold = 0
  for t in target_word:
        if review.find(t) != -1:
            count += 1
  return count > threshold

def get_num_words(review):
  threshold = 0
  words = review.split(' ')
  count = len(list(words))
  return count > threshold

def find_bad_words(review,finded):
  target_word = bad_words
  count = 0
  finded = []
  for t in target_word:
        if review.find(t) != -1:
            finded.append(t)
  return finded

class CustomFeats(BaseEstimator, TransformerMixin):
    def __init__(self):
      self.feat_names = set()

    def fit(self, x, y=None):
        return self

    @staticmethod
    def features(review):
      return {
          'num_word': get_num_words(review),
          'bad_word': get_bad_words(review)
      }

    def get_feature_names(self):
        return list(self.feat_names)
      
    def transform(self, reviews):
      feats = []
      for review in reviews:
        f = self.features(review)
        [self.feat_names.add(k) for k in f] 
        feats.append(f)
      return feats

#feats = make_pipeline(CustomFeats(), DictVectorizer())
feats = FeatureUnion([
     ('custom', make_pipeline(CustomFeats(), DictVectorizer())),
     ('bag_of_words', TfidfVectorizer(stop_words=filtering))
 ])

"""# **Model Klasifikasi**

Algoritma yang diuji:
- Random forest
- KNN
- SVM 
- Decision Tree **bold text**
"""

def classification(feats, model):  
  train_vecs = feats.fit_transform(train_data)
  test_vecs = feats.transform(test_data)
    
  model.fit(train_vecs, train_label)

  train_preds = model.predict(train_vecs)
  test_preds = model.predict(test_vecs)

  cm = confusion_matrix(test_label, test_preds)
  print("Confusion Matrix : \n", cm, " \n")

  report = classification_report(test_label, test_preds)
  print(report)

  return test_preds

"""**Algoritma Random Forest**"""

model_rf = RandomForestClassifier()
y_preds_rf = classification(feats, model_rf)
y_preds_rf

"""**Algoritma Klasifikasi KNN**"""

model_knn= KNeighborsClassifier(n_neighbors=10) 
y_preds_knn = classification(feats, model_knn)
y_preds_knn

"""**Algoritma Klasifikasi Decision Tree**"""

model_dt = DecisionTreeClassifier(min_samples_split=0.4, max_depth=77)
y_preds_dt = classification(feats, model_dt)
y_preds_dt

"""**Algoritma Klasifikasi SVM**"""

model_svm = SVC(C = 10000, kernel = 'rbf')
y_preds_svm = classification(feats, model_svm)
y_preds_svm

"""# **Fungsi Model**

**Berdasarkan pengujian ke-4 algoritma, didapatkan bahwa performa algoritma klasifikasi decision tree lebih unggul dibandingkan yang lainnya dalam melakukan klasifikasi lirik. Maka fungsi model yang dibuat menggunakan algorirma decision tree**
"""

# lirik = ['love you']
# test_vecs = feats.transform(lirik)

# train_vecs = feats.fit_transform(train_data)

# model = DecisionTreeClassifier(min_samples_split=0.4, max_depth=77)
# model.fit(train_vecs, train_label)

# test_preds = model.predict(test_vecs)

# test_preds

def classification_model(test_data):
  teks= [test_data]
  train_vecs = feats.fit_transform(train_data)
  test_vecs = feats.transform(teks)
  model = DecisionTreeClassifier(min_samples_split=0.4, max_depth=77)
  model.fit(train_vecs, train_label)
  test_preds = model.predict(test_vecs)

  if test_preds == 0 :
    return ("This song doesn't contain any badwords")
  else :
    return ("This song contains any badwords")
  return test_preds

"""# **Clasify Test**"""

singer = str(input('Penyanyi : '))
title = str(input('Judul Lagu : '))
lirik = str(input('Lirik Lagu : '))

finded = []
lirik = clean(lirik)
lirik = casefolding(lirik)
find = find_bad_words(lirik,finded)
result = classification_model(lirik)

print(result)
print('Badwords yang ditemukan : ', find)

singer = str(input('Penyanyi : '))
title = str(input('Judul Lagu : '))
lirik = str(input('Lirik Lagu : '))

finded = []
lirik = clean(lirik)
lirik = casefolding(lirik)
find = find_bad_words(lirik,finded)
result = classification_model(lirik)

print(result)
print('Badwords yang ditemukan : ', find)